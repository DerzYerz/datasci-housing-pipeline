{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produces dataset of project times from appended pipeline datasets (\"all_quarters_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import dateutil\n",
    "from dateutil import parser\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Broken Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned/all_quarters_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keep only variables of interest\n",
    "list = ['address', 'apn', 'best_date', 'best_stat','firstfiled', 'report_quarter', 'report_year', 'units', 'unitsnet', 'dbi_permit', 'x', 'y']\n",
    "df = df[list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#consolidate status categories. Start with 3 for now\n",
    "def status_function(value):\n",
    "    if value['best_stat']==\"CONSTRUCTION\":\n",
    "        field = 'Under Construction'\n",
    "    elif (value['best_stat']=='BP APPROVED') | (value['best_stat']=='BP ISSUED') | (value['best_stat']=='BP REINSTATED'):\n",
    "        field = 'Building Permit Approved'\n",
    "    else:\n",
    "        field = 'Proposed'\n",
    "    return field\n",
    "        \n",
    "df['status']=df.apply(status_function, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb = df.groupby(['apn', 'address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_df = gb.get_group(('6019006','340 NAPLES ST'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_df=group_df.sort_values(['best_date', 'report_year', 'report_quarter'], ascending=[True, True, True])\n",
    "group_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_row = group_df.tail(1).copy()\n",
    "        \n",
    "# identify building permit ID. Then fill in rest of quarters with this permit ID.\n",
    "building_permit=np.nan\n",
    "for index, row in group_df.iterrows():\n",
    "    if pd.isnull(row['dbi_permit']) and not pd.isnull(building_permit):\n",
    "        building_permit=building_permit\n",
    "    else:\n",
    "        building_permit = row['dbi_permit']\n",
    "\n",
    "#Identify completion quarter for those projects that have reached completion\n",
    "for index, row in group_df.iterrows():\n",
    "    if row['best_stat'] !='CONSTRUCTION':\n",
    "        comp_quarter= np.nan\n",
    "        comp_year=np.nan\n",
    "    elif row['best_stat'] == 'CONSTRUCTION':\n",
    "        comp_quarter = row['report_quarter']\n",
    "        comp_year = row['report_year']\n",
    "\n",
    "if pd.isnull(comp_quarter):\n",
    "    pass\n",
    "if comp_quarter == 1 and comp_year == 2016:\n",
    "    comp_quarter = np.nan\n",
    "elif comp_quarter == 4:\n",
    "    comp_quarter = 1\n",
    "    comp_year = 1+comp_year\n",
    "else:\n",
    "    comp_quarter = 1+comp_quarter\n",
    "\n",
    "if comp_quarter ==1:\n",
    "    comp_daymth= '01/01'\n",
    "elif comp_quarter ==2:\n",
    "    comp_daymth= '04/01'\n",
    "elif comp_quarter==3:\n",
    "    comp_daymth= '07/01'\n",
    "elif comp_quarter == 4:\n",
    "    comp_daymth= '10/01'\n",
    "elif pd.isnull(comp_quarter):\n",
    "    comp_daymth=np.nan\n",
    "\n",
    "if pd.isnull(comp_daymth):\n",
    "    comp_date = np.nan\n",
    "else:\n",
    "    comp_date = comp_daymth + \"/\" + str(comp_year)\n",
    "\n",
    "#Identify earliest \"firstfiled\" date\n",
    "firstfiled=''\n",
    "for index, row in group_df.iterrows():\n",
    "    if pd.isnull(row['firstfiled']):\n",
    "        continue\n",
    "    else:\n",
    "        if len(firstfiled) ==0:\n",
    "            firstfiled=row['firstfiled']\n",
    "        else:\n",
    "            if dateutil.parser.parse(row['firstfiled']) < dateutil.parser.parse(firstfiled):\n",
    "                firstfiled=row['firstfiled']\n",
    "            else: \n",
    "                firstfiled=firstfiled\n",
    "        \n",
    "#Identify earliest best date\n",
    "earliest_BD = ''\n",
    "for index, row in group_df.iterrows():\n",
    "    if pd.isnull(row['best_date']):\n",
    "        continue\n",
    "    else:\n",
    "        if len(earliest_BD) == 0:\n",
    "            earliest_BD = row['best_date']\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "# Finalize first date variable (minimum of earliest best_date and firstfiled)\n",
    "if firstfiled =='' and earliest_BD !='':\n",
    "    first_date = earliest_BD\n",
    "elif earliest_BD=='' and firstfiled !='':\n",
    "    first_date = firstfiled\n",
    "elif firstfiled !='' and earliest_BD !='':\n",
    "    first_date = min(firstfiled, earliest_BD)\n",
    "\n",
    "# initiate variables. Groups without these dates are blank for these variables.\n",
    "BP_date = ''\n",
    "con_date = ''\n",
    "\n",
    "#Identify first date for all status categories\n",
    "m=0\n",
    "for index, row in group_df.iterrows():\n",
    "    if m == 0:\n",
    "        status_previous = 'blah'\n",
    "    if row['status']=='Building Permit Approved':\n",
    "        if index == 0:\n",
    "            BP_date = row['best_date']\n",
    "        elif index !=0:\n",
    "            if status_previous =='Building Permit Approved':\n",
    "                BP_date=BP_date\n",
    "            else:\n",
    "                BP_date = row['best_date']\n",
    "    elif row['status']=='Under Construction':\n",
    "        if index == 0:\n",
    "            con_date = row['best_date']\n",
    "        elif index !=0:\n",
    "            if status_previous =='Under Construction':\n",
    "                con_date=con_date\n",
    "            else:\n",
    "                con_date = row['best_date']\n",
    "    status_previous = row['status']\n",
    "    m=m+1\n",
    "\n",
    "#Identify latest unit counts\n",
    "units = np.nan\n",
    "for index, row in group_df.iterrows():\n",
    "    if pd.isnull(row['units']):\n",
    "        continue\n",
    "    else:\n",
    "        units = row['units']\n",
    "                \n",
    "#Identify latest net unit counts\n",
    "unitsnet= np.nan\n",
    "for index, row in group_df.iterrows():\n",
    "    if pd.isnull(row['unitsnet']):\n",
    "        continue\n",
    "    else:\n",
    "        unitsnet = row['unitsnet']\n",
    "\n",
    "#a few projects have construction best date after the completion date. In these cases, match the two.\n",
    "if pd.notnull(comp_date):\n",
    "    if dateutil.parser.parse(comp_date) < dateutil.parser.parse(con_date):\n",
    "        comp_date = con_date\n",
    "        \n",
    "last_row['firstfiled']=firstfiled\n",
    "last_row['dbi_permit']= building_permit\n",
    "last_row['comp_date']=comp_date\n",
    "last_row['BP_date'] = BP_date\n",
    "last_row['con_date'] = con_date\n",
    "last_row['first_date']=first_date\n",
    "last_row['latest_project_record_date'] = last_row.best_date\n",
    "last_row['first_project_record_date'] = group_df.iloc[0].best_date\n",
    "last_row['latest_project_status'] = last_row.best_stat\n",
    "last_row['units']=units\n",
    "last_row['unitsnet']=unitsnet\n",
    "\n",
    "## Store a parseable list of all the project states and the dates those states were reported\n",
    "last_row['project_dates'] = str(tuple(group_df.best_date))\n",
    "last_row['project_statuses'] = str(tuple(group_df.best_stat))\n",
    "\n",
    "## Store the project duration in days\n",
    "if not (pd.isnull(comp_date) or pd.isnull(first_date)):\n",
    "    last_row['project_duration_days'] = (dateutil.parser.parse(comp_date) - dateutil.parser.parse(first_date)).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (type(comp_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (type(con_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comp_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_one_record_per_project(df):\n",
    "    \"\"\"\n",
    "    Group the dataset by (apn, address) and then emit one row per (apn, address) pair.\n",
    "    best_date and best_stat will be converted into arrays.\n",
    "    All other attributes will be taken from the record with the most recent `best_date` attribute.\n",
    "    \"\"\"\n",
    "    gb = df.groupby(['apn', 'address'])\n",
    "    for k in gb.groups:\n",
    "        group_df = gb.get_group(k)\n",
    "        group_df = group_df.sort_values(['best_date', 'report_year', 'report_quarter'], ascending=[True, True, True])\n",
    "        last_row = group_df.tail(1).copy()\n",
    "        \n",
    "        # identify building permit ID. Then fill in rest of quarters with this permit ID.\n",
    "        building_permit=np.nan\n",
    "        for index, row in group_df.iterrows():\n",
    "            if pd.isnull(row['dbi_permit']) and not pd.isnull(building_permit):\n",
    "                building_permit=building_permit\n",
    "            else:\n",
    "                building_permit = row['dbi_permit']\n",
    "                \n",
    "        #Identify completion quarter for those projects that have reached completion\n",
    "        for index, row in group_df.iterrows():\n",
    "            if row['best_stat'] !='CONSTRUCTION':\n",
    "                comp_quarter= np.nan\n",
    "                comp_year=np.nan\n",
    "            elif row['best_stat'] == 'CONSTRUCTION':\n",
    "                comp_quarter = row['report_quarter']\n",
    "                comp_year = row['report_year']\n",
    "\n",
    "        if pd.isnull(comp_quarter):\n",
    "            pass\n",
    "        if comp_quarter == 1 and comp_year == 2016:\n",
    "            comp_quarter = np.nan\n",
    "        elif comp_quarter == 4:\n",
    "            comp_quarter = 1\n",
    "            comp_year = 1+comp_year\n",
    "        else:\n",
    "            comp_quarter = 1+comp_quarter\n",
    "            \n",
    "        if comp_quarter ==1:\n",
    "            comp_daymth= '01/01'\n",
    "        elif comp_quarter ==2:\n",
    "            comp_daymth= '04/01'\n",
    "        elif comp_quarter==3:\n",
    "            comp_daymth= '07/01'\n",
    "        elif comp_quarter == 4:\n",
    "            comp_daymth= '10/01'\n",
    "        elif pd.isnull(comp_quarter):\n",
    "            comp_daymth=np.nan\n",
    "\n",
    "        if pd.isnull(comp_daymth):\n",
    "            comp_date = np.nan\n",
    "        else:\n",
    "            comp_date = comp_daymth + \"/\" + str(comp_year)\n",
    "        \n",
    "        #Identify earliest \"firstfiled\" date\n",
    "        firstfiled=''\n",
    "        for index, row in group_df.iterrows():\n",
    "            if pd.isnull(row['firstfiled']):\n",
    "                continue\n",
    "            else:\n",
    "                if len(firstfiled) ==0:\n",
    "                    firstfiled=row['firstfiled']\n",
    "                else:\n",
    "                    if dateutil.parser.parse(row['firstfiled']) < dateutil.parser.parse(firstfiled):\n",
    "                        firstfiled=row['firstfiled']\n",
    "                    else: \n",
    "                        firstfiled=firstfiled\n",
    "        \n",
    "        #Identify earliest best date\n",
    "        earliest_BD = ''\n",
    "        for index, row in group_df.iterrows():\n",
    "            if pd.isnull(row['best_date']):\n",
    "                continue\n",
    "            else:\n",
    "                if len(earliest_BD) == 0:\n",
    "                    earliest_BD = row['best_date']\n",
    "                else:\n",
    "                    continue\n",
    "        \n",
    "        # Finalize first date variable (minimum of earliest best_date and firstfiled)\n",
    "        if firstfiled =='' and earliest_BD !='':\n",
    "            first_date = earliest_BD\n",
    "        elif earliest_BD=='' and firstfiled !='':\n",
    "            first_date = firstfiled\n",
    "        elif firstfiled !='' and earliest_BD !='':\n",
    "            first_date = min(firstfiled, earliest_BD)\n",
    "            \n",
    "        # initiate variables. Groups without these dates are blank for these variables.\n",
    "        BP_date = ''\n",
    "        con_date = ''\n",
    "\n",
    "        #Identify first date for all status categories\n",
    "        m=0\n",
    "        for index, row in group_df.iterrows():\n",
    "            if m == 0:\n",
    "                status_previous = 'blah'\n",
    "            if row['status']=='Building Permit Approved':\n",
    "                if index == 0:\n",
    "                    BP_date = row['best_date']\n",
    "                elif index !=0:\n",
    "                    if status_previous =='Building Permit Approved':\n",
    "                        BP_date=BP_date\n",
    "                    else:\n",
    "                        BP_date = row['best_date']\n",
    "            elif row['status']=='Under Construction':\n",
    "                if index == 0:\n",
    "                    con_date = row['best_date']\n",
    "                elif index !=0:\n",
    "                    if status_previous =='Under Construction':\n",
    "                        con_date=con_date\n",
    "                    else:\n",
    "                        con_date = row['best_date']\n",
    "            status_previous = row['status']\n",
    "            m=m+1\n",
    "            \n",
    "        #Identify latest unit counts\n",
    "        units = np.nan\n",
    "        for index, row in group_df.iterrows():\n",
    "            if pd.isnull(row['units']):\n",
    "                continue\n",
    "            else:\n",
    "                units = row['units']\n",
    "                \n",
    "        #Identify latest net unit counts\n",
    "        unitsnet= np.nan\n",
    "        for index, row in group_df.iterrows():\n",
    "            if pd.isnull(row['unitsnet']):\n",
    "                continue\n",
    "            else:\n",
    "                unitsnet = row['unitsnet']\n",
    "                \n",
    "        #a few projects have construction best date after the completion date. In these cases, match the two.\n",
    "        if pd.notnull(comp_date):\n",
    "            if dateutil.parser.parse(comp_date) < dateutil.parser.parse(con_date):\n",
    "                comp_date = con_date\n",
    "        \n",
    "        last_row['firstfiled']=firstfiled\n",
    "        last_row['dbi_permit']= building_permit\n",
    "        last_row['comp_date']=comp_date\n",
    "        last_row['BP_date'] = BP_date\n",
    "        last_row['con_date'] = con_date\n",
    "        last_row['first_date']=first_date\n",
    "        last_row['latest_project_record_date'] = last_row.best_date\n",
    "        last_row['first_project_record_date'] = group_df.iloc[0].best_date\n",
    "        last_row['latest_project_status'] = last_row.best_stat\n",
    "        last_row['units']=units\n",
    "        last_row['unitsnet']=unitsnet\n",
    "\n",
    "        ## Store a parseable list of all the project states and the dates those states were reported\n",
    "        last_row['project_dates'] = str(tuple(group_df.best_date))\n",
    "        last_row['project_statuses'] = str(tuple(group_df.best_stat))\n",
    "\n",
    "        ## Store the project duration in days\n",
    "        if not (pd.isnull(comp_date) or pd.isnull(first_date)):\n",
    "            last_row['project_duration_days'] = (dateutil.parser.parse(comp_date) - dateutil.parser.parse(first_date)).days\n",
    "\n",
    "        yield last_row\n",
    "\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv(\"cleaned/all_quarters_merged.csv\")\n",
    "    #consolidate status categories. Start with 3 for now\n",
    "    def status_function(value):\n",
    "        if value['best_stat']==\"CONSTRUCTION\":\n",
    "            field = 'Under Construction'\n",
    "        elif (value['best_stat']=='BP APPROVED') | (value['best_stat']=='BP ISSUED') | (value['best_stat']=='BP REINSTATED'):\n",
    "            field = 'Building Permit Approved'\n",
    "        else:\n",
    "            field = 'Proposed'\n",
    "        return field\n",
    "\n",
    "    df['status']=df.apply(status_function, axis=1)\n",
    "    \n",
    "    #keep only variables we want\n",
    "    list = ['address', 'apn', 'best_date', 'best_stat','status', 'firstfiled', 'report_quarter', 'report_year','units','unitsnet', 'dbi_permit', 'x', 'y']\n",
    "    df = df[list]\n",
    "    new_df = pd.concat(convert_to_one_record_per_project(df))\n",
    "    logging.info(\"Writing output ({} rows, {} cols) to data/cleaned/all_quarters__one_record_per_project.csv\".format(*new_df.shape))\n",
    "    new_df.to_csv(\"cleaned/all_quarters__one_record_per_project.csv\")\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First, filter out those projects that are exclusively non-residential (defined as those without units)\n",
    "new_df = new_df[new_df['units'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next, keep only those that reached completion at some point over the time period\n",
    "new_df=new_df[pd.notnull(new_df['comp_date'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Duplicate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df['address_apn']=new_df['address']+new_df['apn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finally, filter out records with duplicate BP Ids\n",
    "new_df[new_df.duplicated('dbi_permit', keep=False)]['address_apn'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df[new_df['address_apn']=='1634 - 1690 PINE ST0647007']['dbi_permit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Same project, different address-apn combination—verified by looking at each address in PIM\n",
    "new_df[new_df['dbi_permit']==201312184508.00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#explore duplicated\n",
    "new_df[new_df['address']=='2155 WEBSTER ST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df[new_df['dbi_permit']=='200705010136']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df[new_df['project_duration_days']<0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Data Cleaning\n",
    "Based off of identified duplicates in the previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#decided that both this and its duplicate BP at 1169 Market Street are two phases of the same project. Same start date, different end dates\n",
    "new_df.loc[(new_df['address']=='1190 MISSION ST') & (new_df['apn']=='3702052'), 'first_date'] = '2003-07-15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this has a duplicate, same address, different APN\n",
    "new_df=new_df[(new_df['address']!='3575 GEARY BL') | (new_df['apn']=='1084010')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#same project, happening at different periods\n",
    "new_df.loc[(new_df['address']=='1634-1690 PINE ST') & (new_df['apn']=='0647007'), 'comp_date']='07/01/2016'\n",
    "new_df=new_df[(new_df['address']!='1634 - 1690 PINE ST') | (new_df['apn']=='0647007')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df.loc[(new_df['address']=='1634-1690 PINE ST') & (new_df['apn']=='0647007')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Be sure to redo project duration after all manual cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#do median time based on neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#breakdown time to completion by stage for those projects that this can be done for"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
